{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantized Model Cleanup\n",
    "This notebook takes the finn-onnx FACILE model exported by the quant_train notebook and cleans it up. This notebook stops before converting to hls layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in FINN and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from finn.util.test import get_test_model_trained\n",
    "import brevitas.onnx as bo\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.infer_shapes import InferShapes\n",
    "from finn.transformation.fold_constants import FoldConstants\n",
    "from finn.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "from finn.transformation.infer_datatypes import InferDataTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and tidy up brevitas export\n",
    "model = ModelWrapper(\"quant_models/facileV2_4b_1.onnx\")\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "#model.save(\"quant_models/facileV2_4b_500_tidy.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor name: global_in\n",
      "Output tensor name: global_out\n",
      "input shape: [1, 14]\n",
      "out shape: [1, 1]\n",
      "input dtype: DataType.UINT4\n",
      "out dtype: DataType.UINT4\n"
     ]
    }
   ],
   "source": [
    "#print input and output tensors and data types/shapes\n",
    "from finn.core.datatype import DataType\n",
    "\n",
    "in_tensor = model.graph.input[0].name\n",
    "out_tensor = model.graph.output[0].name\n",
    "print(\"Input tensor name: %s\" % in_tensor)\n",
    "print(\"Output tensor name: %s\" % out_tensor)\n",
    "in_shape = model.get_tensor_shape(in_tensor)\n",
    "out_shape = model.get_tensor_shape(out_tensor)\n",
    "print(\"input shape: \" + str(in_shape))\n",
    "print(\"out shape: \" + str(out_shape))\n",
    "model.set_tensor_datatype(in_tensor, DataType.UINT4)\n",
    "model.set_tensor_datatype(out_tensor, DataType.UINT4)\n",
    "in_dtype = model.get_tensor_datatype(in_tensor)\n",
    "out_dtype = model.get_tensor_datatype(out_tensor)\n",
    "print(\"input dtype: \" + str(in_dtype))\n",
    "print(\"out dtype: \" + str(out_dtype))\n",
    "model.save(\"quant_models/facileV2_4b_1_tidy.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'quant_models/facileV2_4b_1_tidy.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f2578bc76a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize net in netron\n",
    "from finn.util.visualization import showInNetron\n",
    "showInNetron(\"quant_models/facileV2_4b_1_tidy.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (229538, 14)\n",
      "X_val shape: (12752, 14)\n",
      "X_test shape: (12752, 14)\n",
      "Y_train shape: (229538, 1)\n",
      "Y_val shape: (12752, 1)\n",
      "Y_test shape: (12752, 1)\n",
      "Using saved split data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/finn-base/src/finn/util/basic.py:380: UserWarning: The values of tensor global_in can't be represented with the set FINN datatype (DataType.UINT4), they will be rounded to match the FINN datatype.\n",
      "  \"FINN datatype.\".format(tensor, dtype)\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Rounding error is too high to match set FINN\n            datatype (DataType.UINT4) for input global_in",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-00967b61b76c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0minp_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0min_tensor\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mexp_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mout_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexe_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/finn-base/src/finn/core/onnx_exec.py\u001b[0m in \u001b[0;36mexecute_onnx\u001b[0;34m(model, input_dict, return_full_exec_context, start_node, end_node)\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0;31m# round input values to match quantization annotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 execution_context = sanitize_quant_values(\n\u001b[0;32m--> 204\u001b[0;31m                     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 )\n\u001b[1;32m    206\u001b[0m             \u001b[0mexecute_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_full_exec_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/finn-base/src/finn/util/basic.py\u001b[0m in \u001b[0;36msanitize_quant_values\u001b[0;34m(model, node_tensors, execution_context, check_values)\u001b[0m\n\u001b[1;32m    399\u001b[0m                 \"\"\"Rounding error is too high to match set FINN\n\u001b[1;32m    400\u001b[0m             datatype ({}) for input {}\"\"\".format(\n\u001b[0;32m--> 401\u001b[0;31m                     \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m                 )\n\u001b[1;32m    403\u001b[0m             )\n",
      "\u001b[0;31mException\u001b[0m: Rounding error is too high to match set FINN\n            datatype (DataType.UINT4) for input global_in"
     ]
    }
   ],
   "source": [
    "#test inference\n",
    "from finn.core.onnx_exec import execute_onnx as exe_onnx\n",
    "from utils import load_torch_datasets\n",
    "import numpy as np\n",
    "\n",
    "train, test, valid, shape = load_torch_datasets()\n",
    "valid_size = len(valid)\n",
    "batch_size = 1\n",
    "num_batches = int(valid_size/batch_size)\n",
    "running_error_square = 0\n",
    "for i in range(0, num_batches):\n",
    "    batch = valid[(i*batch_size):((i+1)*batch_size)]\n",
    "    inp = batch[0].numpy()\n",
    "    inp_dict = {in_tensor : inp}\n",
    "    exp_out = batch[1].numpy()\n",
    "    out_dict = exe_onnx(model, inp_dict)\n",
    "    out = out_dict[out_tensor]\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
